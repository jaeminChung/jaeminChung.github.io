---
layout: post
title:  "Machine learning activation function"
date:   2017-11-14 12:44:13
categories: ML
permalink: /archivers/ml-activation-function
use_math: true
---

Activation Function

* Sigmoid
\begin{align\*}
  \sigma(x) = \frac{1}{(1+e^2)}
\end{align\*}
* tanh
\begin{align\*}
  tanh(x)
\end{align\*}
* ReLU : Rectified Linear Unit
\begin{align\*}
  max(0,x)
\end{align\*}
* Leaky ReLU
\begin{align\*}
  max(0.1x,x)
\end{align\*}
